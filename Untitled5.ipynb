{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q kaggle\n",
    "from google.colab import files\n",
    "\n",
    "print('Upload file {kaggle.json} :\\n')\n",
    "files.upload() \n",
    "\n",
    "! mkdir ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "! kaggle datasets download --unzip -d defileroff/comic-faces-paired-synthetic-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df809c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, os, random\n",
    "import random, PIL\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bec917",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = list(map(lambda name:os.path.join(\"/content/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/faces\",name), os.listdir(\"/content/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/faces\")))\n",
    "test_paths  = paths[:len(paths)//3]\n",
    "train_paths = paths[len(paths)//3+1:] \n",
    "paths1 = list(map(lambda name:os.path.join(\"/content/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/comics\",name), os.listdir(\"/content/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/comics\")))\n",
    "test_paths1  = paths1[:len(paths)//3]\n",
    "train_paths1 = paths1[len(paths)//3+1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37528fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating training and test set\n",
    "training_set=train_paths+train_paths1  #6666 + 6666 = 13332 observations \n",
    "test_set=test_paths1+test_paths #3333 + 3333 = 6666 observations\n",
    "all_paths= training_set + test_set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes(batch_size, epochs, data):\n",
    "  all_indexes= random.Random(10).choices(range(len(data)), k=batch_size*epochs)\n",
    "  return all_indexes\n",
    "\n",
    "#getting indexes from the training set used in the validation approach\n",
    "all_indexes=get_indexes(100, 100, training_set)\n",
    "all_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c58af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the proportion of classes after the random draw\n",
    "face_list=[]\n",
    "for i in all_indexes:\n",
    "  if i < 6666:\n",
    "    face_list.append(i)\n",
    "\n",
    "comic_list=[]\n",
    "for i in all_indexes:\n",
    "  if i >= 6666:\n",
    "    comic_list.append(i)\n",
    "\n",
    "print(len(face_list), len(np.unique(face_list)), len(comic_list), len(np.unique(comic_list))) #the fraction of faces and comics images randomly drawn and their unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_start_finish=[]\n",
    "f=0\n",
    "for i in range (100):\n",
    "    list_start_finish.append([f, f+99])\n",
    "    f+=100\n",
    "list_start_finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68411b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions able to load images and assig them the label[1, 0] for comics and [0, 1] for face\n",
    "def convert_image_to_array(path, size=(128, 128)):\n",
    "    return tf.keras.utils.img_to_array(PIL.Image.open(path).resize(size, PIL.Image.NEAREST)).mean(-1)/255 #tf.keras.utils.img_to_array = Converts a PIL Image instance to a Numpy array.\n",
    "\n",
    "def assign_label(path): \n",
    "    return [0,1] if \"faces\" in path else [1,0]\n",
    "\n",
    "def create_batch(data, indexes, image_shape = (128, 128)):\n",
    "    X = np.stack([convert_image_to_array(data[p], size=image_shape) for p in indexes])\n",
    "    Y = np.array([assign_label(data[p]) for p in indexes])\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420db984",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=create_batch(training_set, all_indexes[list_start_finish[0][0]: list_start_finish[0][1]] )\n",
    "plt.imshow(X[1])\n",
    "print(f\"label : {Y[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfd3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining loss function and optimizer type\n",
    "optim   = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "lossfn  = tf.keras.losses.CategoricalCrossentropy(from_logits=True, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57846e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function\n",
    "def train_step(X, Y, model):\n",
    "    \n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        X = tf.cast(tf.convert_to_tensor(X), tf.float32)\n",
    "        Y = tf.cast(tf.convert_to_tensor(Y), tf.float32)\n",
    "        P = model(X, training=True)\n",
    "        loss = lossfn(Y, P)\n",
    "        \n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optim.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "\n",
    "    accuracy = tf.reduce_sum(tf.cast(tf.argmax(Y,-1) == tf.argmax(P,-1), tf.int32))/X.shape[0] \n",
    "\n",
    "    return loss.numpy(), accuracy.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21803ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the 3 models\n",
    "#MODEL-1\n",
    "class Model_1(tf.keras.Model):\n",
    "    def __init__(self, batch_size, image_size, n_filters1, filter_size, padding, n_nodes):\n",
    "        super(Model_1, self).__init__()\n",
    "        \n",
    "        self.convolutional1 = tf.keras.layers.Conv2D(n_filters1, filter_size, padding=padding, activation='relu', kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=10)) \n",
    "        self.maxpooling1    = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.flat1 = tf.keras.layers.Flatten() \n",
    "        \n",
    "        self.dense1  = tf.keras.layers.Dense(n_nodes, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)) \n",
    "        self.dense2  = tf.keras.layers.Dense(2 , activation=\"softmax\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=123))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.expand_dims(x, -1)\n",
    "        x = self.maxpooling1(self.convolutional1(x))\n",
    "        x = self.flat1(x)\n",
    "        x = self.dense2(self.dense1(x))\n",
    "        return x[:, 0:2]\n",
    "\n",
    "######################################################################################################################################################################################à\n",
    "\n",
    "#MODEL-2\n",
    "class Model_2(tf.keras.Model):\n",
    "    def __init__(self, batch_size, image_size, n_filters1, n_filters2, n_filters3, filter_size, padding, n_nodes):\n",
    "        super(Model_2, self).__init__()\n",
    "        \n",
    "        self.convolutional1 = tf.keras.layers.Conv2D(n_filters1, filter_size, padding=padding, activation='relu', kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=10)) \n",
    "        self.maxpooling1    = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.convolutional2 = tf.keras.layers.Conv2D(n_filters2, filter_size, padding=padding, activation='relu', kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=20)) \n",
    "        self.maxpooling2    = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.convolutional3 = tf.keras.layers.Conv2D(n_filters3, filter_size, padding=padding, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=30))  \n",
    "        self.maxpooling3    = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.flat1          = tf.keras.layers.Flatten() \n",
    "        \n",
    "        self.dense1  = tf.keras.layers.Dense(n_nodes, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)) \n",
    "        self.dense2  = tf.keras.layers.Dense(2 , activation=\"softmax\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=123))\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.expand_dims(x, -1)\n",
    "        x = self.maxpooling1(self.convolutional1(x))\n",
    "        x = self.maxpooling2(self.convolutional2(x))\n",
    "        x = self.maxpooling3(self.convolutional3(x))\n",
    "        x = self.flat1(x)\n",
    "        x = self.dense2(self.dense1(x))\n",
    "        return x[:, 0:2]\n",
    "\n",
    "#################################################################################################################################################################################à\n",
    "\n",
    "#MODEL-3\n",
    "class Model_3(tf.keras.Model):\n",
    "    def __init__(self, batch_size, image_size, n_filters1, n_filters2, n_filters3, n_filters4, n_filters5, filter_size, padding, n_nodes):\n",
    "        super(Model_3, self).__init__()\n",
    "        \n",
    "        self.convolutional1 = tf.keras.layers.Conv2D(n_filters1, filter_size, padding=padding, activation='relu', kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=10)) \n",
    "        self.maxpooling1    = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.convolutional2 = tf.keras.layers.Conv2D(n_filters2, filter_size, padding=padding, activation='relu', kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=20)) \n",
    "        self.maxpooling2    = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.convolutional3 = tf.keras.layers.Conv2D(n_filters3, filter_size, padding=padding, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=30))  \n",
    "        self.maxpooling3    = tf.keras.layers.MaxPooling2D((2, 2)) \n",
    "        self.convolutional4 = tf.keras.layers.Conv2D(n_filters4, filter_size, padding=padding, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=40)) \n",
    "        self.maxpooling4    = tf.keras.layers.MaxPooling2D((2,2)) \n",
    "        self.convolutional5 = tf.keras.layers.Conv2D(n_filters5, filter_size, padding=padding, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=50)) \n",
    "        self.maxpooling5    = tf.keras.layers.MaxPooling2D((2,2)) \n",
    "        self.flat1          = tf.keras.layers.Flatten() \n",
    "        \n",
    "        self.dense1  = tf.keras.layers.Dense(n_nodes, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)) \n",
    "        self.dense2  = tf.keras.layers.Dense(2 , activation=\"softmax\", kernel_initializer=initializers.RandomNormal(mean=0.0, stddev=0.05, seed=123)) \n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.expand_dims(x, -1)\n",
    "        x = self.maxpooling1(self.convolutional1(x))\n",
    "        x = self.maxpooling2(self.convolutional2(x))\n",
    "        x = self.maxpooling3(self.convolutional3(x))\n",
    "        x = self.maxpooling4(self.convolutional4(x))\n",
    "        x = self.maxpooling5(self.convolutional5(x))\n",
    "        x = self.flat1(x)\n",
    "        x = self.dense2(self.dense1(x))\n",
    "        return x[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf71f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRID SEARCH\n",
    "\n",
    "structures= [Model_1, Model_2, Model_3]\n",
    "n_conv1= [10, 32]\n",
    "n_conv2=[[10, 20, 30], [32, 64, 128]]\n",
    "n_conv3=[[10, 20, 30, 40, 50], [32, 64, 128, 256, 512]]\n",
    "n_dense=[10, 20]\n",
    "type_padding=[\"valid\", \"same\"]\n",
    "#size_filter=[3]\n",
    "batch_size=100\n",
    "image_shape=(128,128)\n",
    "best_score=0\n",
    "counter=0\n",
    "accuracy_epochs=[]\n",
    "\n",
    "for i in range(len(structures)):\n",
    "\n",
    "  #FIRST STRUCTURE\n",
    "  if i == 0:\n",
    "    for c in range(len(n_conv1)):\n",
    "      for d in range(len(n_dense)):\n",
    "        for p in range(len(type_padding)):\n",
    "          model1 = structures[i](batch_size, image_shape, n_conv1[c], 3, type_padding[p], n_dense[d])\n",
    "          #training phase\n",
    "          for t in range(100):\n",
    "            start= list_start_finish[t][0]\n",
    "            finish= list_start_finish[t][1]\n",
    "            X,Y = create_batch(training_set, all_indexes[start:finish], image_shape=image_shape)\n",
    "            l,a = train_step(X, Y, model=model1)\n",
    "            accuracy_epochs.append(a)\n",
    "            print(f\"\\r model: {counter+1} with parameters: {n_conv1[c], 3, type_padding[p], n_dense[d]}, batch: {t+1}, loss: {l}, accuracy: {a}\", end=\"    \")\n",
    "\n",
    "          #testing phase\n",
    "\n",
    "          true_positive, false_positive, false_negative, true_negative = 0, 0, 0, 0\n",
    "          paths = test_set\n",
    "          for g,j in enumerate(paths):\n",
    "            X = convert_image_to_array(j, size=image_shape)\n",
    "            Y = assign_label(j)\n",
    "            P = tf.round(model1(X.reshape(1,image_shape[0],image_shape[1]), training=True)).numpy()[0]\n",
    "            Y,P=tf.argmax(Y, -1).numpy(), tf.argmax(P, -1).numpy()\n",
    "\n",
    "            if Y == 1 and P == 1: true_positive  = true_positive + 1\n",
    "            if Y == 0 and P == 1: false_positive = false_positive + 1\n",
    "            if Y == 1 and P == 0: false_negative = false_negative + 1\n",
    "            if Y == 0 and P == 0: true_negative  = true_negative + 1\n",
    "            acc = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "            print(f\"\\r model: {counter+1} with parameters: {n_conv1[c], 3, type_padding[p], n_dense[d]}, {g+1}/{len(paths)}, acc: {acc}\",end=\"\")\n",
    "\n",
    "          counter+=1\n",
    "\n",
    "          if acc>best_score:\n",
    "            best_score=acc\n",
    "            best_parameters=[]\n",
    "            best_parameters.append([n_conv1[c], 3, type_padding[p], n_dense[d]])\n",
    "            best_model= model1\n",
    "            accuracy_epochs_best_model=accuracy_epochs\n",
    "\n",
    "\n",
    "          else:\n",
    "            best_score=best_score\n",
    "\n",
    "          accuracy_epochs=[]\n",
    "\n",
    "          \n",
    "\n",
    "  #SECOND STRUCTURE\n",
    "  elif i==1:\n",
    "    for c in range(len(n_conv2)):\n",
    "      for d in range(len(n_dense)):\n",
    "        for p in range(len(type_padding)):\n",
    "          model1 = structures[i](batch_size, image_shape, n_conv2[c][0], n_conv2[c][1], n_conv2[c][2], 3, type_padding[p], n_dense[d])\n",
    "          #training phase\n",
    "          for t in range(100):\n",
    "            start= list_start_finish[t][0]\n",
    "            finish= list_start_finish[t][1]\n",
    "            X,Y = create_batch(training_set, all_indexes[start:finish], image_shape=image_shape)\n",
    "            l,a = train_step(X, Y, model=model1)\n",
    "            accuracy_epochs.append(a)\n",
    "            print(f\"\\r model: {counter+1} with parameters: {n_conv2[c][0], n_conv2[c][1], n_conv2[c][2], 3, type_padding[p], n_dense[d]}, batch: {t+1}, loss: {l}, accuracy: {a}\", end=\"    \")\n",
    "\n",
    "          #testing phase\n",
    "\n",
    "          true_positive, false_positive, false_negative, true_negative = 0, 0, 0, 0\n",
    "          paths = test_set\n",
    "          for g,j in enumerate(paths):\n",
    "            X = convert_image_to_array(j, size=image_shape)\n",
    "            Y = assign_label(j)\n",
    "            P = tf.round(model1(X.reshape(1,image_shape[0],image_shape[1]), training=True)).numpy()[0]\n",
    "            Y,P=tf.argmax(Y, -1).numpy(), tf.argmax(P, -1).numpy()\n",
    "\n",
    "            if Y == 1 and P == 1: true_positive  = true_positive + 1\n",
    "            if Y == 0 and P == 1: false_positive = false_positive + 1\n",
    "            if Y == 1 and P == 0: false_negative = false_negative + 1\n",
    "            if Y == 0 and P == 0: true_negative  = true_negative + 1\n",
    "            acc = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "            print(f\"\\r model: {counter+1} with parameters: {n_conv2[c][0], n_conv2[c][1], n_conv2[c][2], 3, type_padding[p], n_dense[d]}, {g+1}/{len(paths)}, acc: {acc}\",end=\"\")\n",
    "\n",
    "          counter+=1\n",
    "\n",
    "          if acc>best_score:\n",
    "            best_score=acc\n",
    "            best_parameters=[]\n",
    "            best_parameters.append([n_conv2[c][0], n_conv2[c][1], n_conv2[c][2], 3, type_padding[p], n_dense[d]])\n",
    "            best_model= model1\n",
    "            accuracy_epochs_best_model=accuracy_epochs\n",
    "\n",
    "          else:\n",
    "            best_score=best_score\n",
    "\n",
    "          accuracy_epochs=[]\n",
    "\n",
    "\n",
    "  #THIRD STRUCTURE\n",
    "  else:\n",
    "    for c in range(len(n_conv3)):\n",
    "      for d in range(len(n_dense)):\n",
    "        for p in range(len(type_padding)):\n",
    "          model1 = structures[i](batch_size, image_shape, n_conv3[c][0], n_conv3[c][1], n_conv3[c][2], n_conv3[c][3], n_conv3[c][4], 3, type_padding[p], n_dense[d])\n",
    "          #training phase\n",
    "          for t in range(100):\n",
    "            start= list_start_finish[t][0]\n",
    "            finish= list_start_finish[t][1]\n",
    "            X,Y = create_batch(training_set, all_indexes[start:finish], image_shape=image_shape)\n",
    "            l,a = train_step(X, Y, model=model1)\n",
    "            accuracy_epochs.append(a)\n",
    "            print(f\"\\r model: {counter+1} with parameters: {n_conv3[c][0], n_conv3[c][1], n_conv3[c][2], n_conv3[c][3], n_conv3[c][4], 3, type_padding[p], n_dense[d]}, batch: {t}, loss: {l}, accuracy: {a}\", end=\"    \")\n",
    "\n",
    "          #testing phase\n",
    "          true_positive, false_positive, false_negative, true_negative = 0, 0, 0, 0\n",
    "          paths = test_set\n",
    "          for g,j in enumerate(paths):\n",
    "            X = convert_image_to_array(j, size=image_shape)\n",
    "            Y = assign_label(j)\n",
    "            P = tf.round(model1(X.reshape(1,image_shape[0],image_shape[1]), training=True)).numpy()[0]\n",
    "            Y,P=tf.argmax(Y, -1).numpy(), tf.argmax(P, -1).numpy()\n",
    "\n",
    "            if Y == 1 and P == 1: true_positive  = true_positive + 1\n",
    "            if Y == 0 and P == 1: false_positive = false_positive + 1\n",
    "            if Y == 1 and P == 0: false_negative = false_negative + 1\n",
    "            if Y == 0 and P == 0: true_negative  = true_negative + 1\n",
    "            acc = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "            print(f\"\\r model: {counter+1} with parameters: {n_conv3[c][0], n_conv3[c][1], n_conv3[c][2], n_conv3[c][3], n_conv3[c][4], 3, type_padding[p], n_dense[d]}, {g+1}/{len(paths)}, acc: {acc}\",end=\"\")\n",
    "\n",
    "          counter+=1\n",
    "\n",
    "          if acc>best_score:\n",
    "            best_score=acc\n",
    "            best_parameters=[]\n",
    "            best_parameters.append([n_conv3[c][0], n_conv3[c][1], n_conv3[c][2], n_conv3[c][3], n_conv3[c][4], 3, type_padding[p], n_dense[d]])\n",
    "            best_model= model1\n",
    "            accuracy_epochs_best_model=accuracy_epochs\n",
    "\n",
    "          else:\n",
    "            best_score=best_score\n",
    "\n",
    "          accuracy_epochs=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc3b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111123ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74342f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=create_batch(test_set, [5, 5000])\n",
    "plt.imshow(X[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[1])\n",
    "print(Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc7473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#veryfing if the prdictions of those two images are correct\n",
    "P1=tf.round(best_model(X[0].reshape(1, image_shape[0], image_shape[1]), training=True)).numpy()[0]\n",
    "P2=tf.round(best_model(X[1].reshape(1, image_shape[0], image_shape[1]), training=True)).numpy()[0]\n",
    "print(P1, P2) #predictions are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the fraction of unique observations used during the training\n",
    "len(np.unique(all_indexes))/len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffb13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the theoretical fractions of observations used during the training belonging to the training set, considering a random draw with repelacement of size 10000\n",
    "print((1-(1/len(training_set)))**10000, 1-(1-(1/len(training_set)))**10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7673daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy in the training set composed by observations randomly drawn with replacement \n",
    "true_positive, false_positive, false_negative, true_negative = 0, 0, 0, 0\n",
    "training_set2=[training_set[i] for i in np.unique(all_indexes)]\n",
    "training_set2\n",
    "paths = training_set2\n",
    "for g,j in enumerate(paths):\n",
    "  X = convert_image_to_array(j, size=image_shape)\n",
    "  Y = assign_label(j)\n",
    "  P = tf.round(best_model(X.reshape(1,image_shape[0],image_shape[1]), training=True)).numpy()[0]\n",
    "  Y,P=tf.argmax(Y, -1).numpy(), tf.argmax(P, -1).numpy()\n",
    "\n",
    "  if Y == 1 and P == 1: true_positive  = true_positive + 1\n",
    "  if Y == 0 and P == 1: false_positive = false_positive + 1\n",
    "  if Y == 1 and P == 0: false_negative = false_negative + 1\n",
    "  if Y == 0 and P == 0: true_negative  = true_negative + 1\n",
    "  acc_train = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "  print(f\"\\r model: {counter}, {g+1}/{len(paths)}, acc_train: {acc_train}\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy for the observations inside the training set not seen during the training\n",
    "true_positive, false_positive, false_negative, true_negative = 0, 0, 0, 0\n",
    "test_set2=[training_set[i] for i in range(len(training_set)) if i not in all_indexes]\n",
    "paths = test_set2\n",
    "for g,j in enumerate(paths):\n",
    "  X = convert_image_to_array(j, size=image_shape)\n",
    "  Y = assign_label(j)\n",
    "  P = tf.round(best_model(X.reshape(1,image_shape[0],image_shape[1]), training=True)).numpy()[0]\n",
    "  Y,P=tf.argmax(Y, -1).numpy(), tf.argmax(P, -1).numpy()\n",
    "\n",
    "  if Y == 1 and P == 1: true_positive  = true_positive + 1\n",
    "  if Y == 0 and P == 1: false_positive = false_positive + 1\n",
    "  if Y == 1 and P == 0: false_negative = false_negative + 1\n",
    "  if Y == 0 and P == 0: true_negative  = true_negative + 1\n",
    "  acc_train_test = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "  print(f\"\\r model: {counter}, {g+1}/{len(paths)}, acc_train_test: {acc_train_test}\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the accuracy in each class (inside the test set) for the best model\n",
    "\n",
    "true_positive, false_positive, false_negative, true_negative = 0, 0, 0, 0\n",
    "paths = test_set[0:3333]\n",
    "for g,j in enumerate(paths):\n",
    "  X = convert_image_to_array(j, size=image_shape)\n",
    "  Y = assign_label(j)\n",
    "  P = tf.round(best_model(X.reshape(1,image_shape[0],image_shape[1]), training=True)).numpy()[0]\n",
    "  Y,P=tf.argmax(Y, -1).numpy(), tf.argmax(P, -1).numpy()\n",
    "\n",
    "  if Y == 1 and P == 1: true_positive  = true_positive + 1\n",
    "  if Y == 0 and P == 1: false_positive = false_positive + 1\n",
    "  if Y == 1 and P == 0: false_negative = false_negative + 1\n",
    "  if Y == 0 and P == 0: true_negative  = true_negative + 1\n",
    "  acc_comics = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "  print(f\"\\r model: {counter}, {g+1}/{len(paths)}, acc_comics: {acc_comics}\",end=\"\")\n",
    "\n",
    "\n",
    "true_positive, false_positive, false_negative, true_negative = 0, 0, 0, 0\n",
    "paths = test_set[3333:6666]\n",
    "for g,j in enumerate(paths):\n",
    "  X = convert_image_to_array(j, size=image_shape)\n",
    "  Y = assign_label(j)\n",
    "  P = tf.round(best_model(X.reshape(1,image_shape[0],image_shape[1]), training=True)).numpy()[0]\n",
    "  Y,P=tf.argmax(Y, -1).numpy(), tf.argmax(P, -1).numpy()\n",
    "\n",
    "  if Y == 1 and P == 1: true_positive  = true_positive + 1\n",
    "  if Y == 0 and P == 1: false_positive = false_positive + 1\n",
    "  if Y == 1 and P == 0: false_negative = false_negative + 1\n",
    "  if Y == 0 and P == 0: true_negative  = true_negative + 1\n",
    "  acc_faces = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "  print(f\"\\r model: {counter}, {g+1}/{len(paths)}, acc_faces: {acc_faces}\",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb3626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_comics, acc_faces, (acc_comics+acc_faces)/2)     #the accuracy in both classes are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b41203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolution of accuracy in the epochs for best model\n",
    "\n",
    "x_axis=[i for i in range(100)]\n",
    "plt.plot(x_axis, accuracy_epochs_best_model, label= \"accuracy in epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Evolution of accuracy in the epochs for the best model\")\n",
    "plt.legend()\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
